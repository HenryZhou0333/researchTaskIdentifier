{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import search_engine\n",
    "import math\n",
    "from search_engine import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('C04-1107', 1.7372608314662896), ('W01-0507', 1.6136403484203732), ('C04-1109', 1.5996229743198276), ('C02-1020', 1.5667349294142505), ('I05-1033', 1.5504185928822833), ('W12-2424', 1.5297938446636825), ('W03-0429', 1.527618218545323), ('W13-2017', 1.503366918918143), ('P07-2017', 1.5020809908768378), ('W04-3104', 1.4886173235231233)]\n"
     ]
    }
   ],
   "source": [
    "f = open('index_v2','rb')\n",
    "index = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "query = 'support vector machines'\n",
    "# Retrieve will return a ranked list of tuples of the form (documentID, documentScore).\n",
    "print(Retrieve(query,index,1000,'nofeedback',0.1,10,50,0.9)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pickle.load(open('AllDataPickle_v2.pk','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_keys = data.keys()\n",
    "fw_keys = []\n",
    "num_FW = 0\n",
    "last_nonKey = \"\"\n",
    "for key in data_keys:\n",
    "    curr_FW = data[key][-1]\n",
    "    if not (curr_FW == \"\"):\n",
    "        num_FW = num_FW + 1\n",
    "        fw_keys.append(key)\n",
    "    else:\n",
    "        last_nonKey = key\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.302585092994046\n"
     ]
    }
   ],
   "source": [
    "print (log(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_score(data, results):\n",
    "    dat_score = 0\n",
    "    t_c = 2014\n",
    "    rank = 0\n",
    "    denom = 0\n",
    "    topK = 10\n",
    "    avg_year = 0\n",
    "    avg_score = 0\n",
    "    for (key, rel_score) in results[0:topK]:\n",
    "        rank = rank + 1;\n",
    "        if (rank == 1):\n",
    "            denom = rel_score\n",
    "        t_d = data[key][2]\n",
    "        if (t_c == t_d) or (rel_score/denom < 0.01):\n",
    "            print (key, rel_score/denom)\n",
    "        dat_score = dat_score + exp(t_d - t_d)*(rel_score/denom)\n",
    "        avg_score = rel_score/denom\n",
    "        avg_year = avg_year + t_d\n",
    "        #print(key + \" \" + str(t_d))\n",
    "    print (avg_year/topK, avg_score/topK)\n",
    "    return dat_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W13-4906 \n",
      "however, for interested people, the sources are freely available9, to be packaged in a near future.\n",
      "2007.2 0.06989732893257064\n",
      "W04-0103 \n",
      "some of the questions that we would like to address in the future include modelling of optional schwa deletion in bengali compound words, evolution of morpho-phonology for bengali verb systems, and modelling of dialect diversity using diachronic clues.\n",
      "more realistic, yet manageable computational frameworks for holistic or detailed modelling of language evolution can also be an interesting area of future research.\n",
      "2007.9 0.012859630644841228\n",
      "E99-1005 \n",
      "future research as to identify how this approach can be generalised to unseen data.\n",
      "2008.6 0.06165574336094869\n",
      "W98-0301 \n",
      "it is the purpose of future research to improve the algorithm described here and to investigate the benefits of using more sophisticated methods, such as part of speech tagging and syntactic parsing.\n",
      "2005.3 0.0706649682953532\n",
      "W08-1802 \n",
      "in future work we plan to evaluate how phrase type (noun vs. verb vs. preposition) affects ir performance.\n",
      "2004.8 0.044797020197477534\n",
      "W10-3703 \n",
      "the work is in progress and we hope the emotion classification and the event classification will be compared to determine their underlining relations and hope that more applications can be found in our future work based on cikb.\n",
      "2008.4 0.02415938419222837\n",
      "P13-1107 \n",
      "in the future we will extend our method to discover other types of information morphs, such as events and nominal mentions.\n",
      "2008.0 0.04774297292014238\n",
      "H94-1078 \n",
      "our near-future goal is to combine these two technologies so that real-time, high-accuracy large-vocabulary speech recognition can be achieved.\n",
      "1993.7 0.025212660255923735\n",
      "P08-1106 \n",
      "future work will focus on developing methodologies for computer-assisted back-of-the-book indexing, as well as on the use of the automatically extracted indexes in improving the browsing of digital libraries.\n",
      "2004.5 0.028349119676327788\n",
      "C08-3003 \n",
      "now, in a next future, we have the ambition of using the toolchain for parsing large raw corpora in different languages.\n",
      "2007.2 0.024863541718623157\n"
     ]
    }
   ],
   "source": [
    "lta_scores = []\n",
    "for key in fw_keys[:10]:\n",
    "    query = data[key][-1]\n",
    "    print (key , query)\n",
    "    result = Retrieve(query,index,1000,'nofeedback',0.1,10,50,0.9)# [0:10]\n",
    "    lta_scores.append( (key,get_score(data,result) )  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('W13-4906', 8.269331636383164),\n",
       " ('W04-0103', 2.59313474591267),\n",
       " ('E99-1005', 6.966667875554385),\n",
       " ('W98-0301', 8.053860826548048),\n",
       " ('W08-1802', 5.729451877959522),\n",
       " ('W10-3703', 3.557416423251796),\n",
       " ('P13-1107', 6.025759387926342),\n",
       " ('H94-1078', 3.6585401056257907),\n",
       " ('P08-1106', 3.91800584098089),\n",
       " ('C08-3003', 3.4002098531342395)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lta_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
