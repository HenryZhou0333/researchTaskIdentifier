{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import search_engine\n",
    "import math\n",
    "from search_engine import *\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from collections import defaultdict\n",
    "import example_pos\n",
    "from example_pos import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('P11-2088', 1.560755882714912), ('N13-2011', 1.5568653873920246), ('W06-1650', 1.4811053903847555), ('W11-1402', 1.3347899903364284), ('W12-0608', 1.2852938587875227), ('W10-0207', 1.2849812980588509), ('J11-1014', 1.1836936383180425), ('C10-2035', 1.1508444478262378), ('W10-1205', 1.1271211985155167), ('W13-5008', 1.0433620928310816)]\n"
     ]
    }
   ],
   "source": [
    "#original index-contains just the abstract\n",
    "# index_v2 contains the abstract introduction and conclusion\n",
    "# \n",
    "f = open('index_title_abs','rb')\n",
    "index = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "query = 'review help suggest'\n",
    "# Retrieve will return a ranked list of tuples of the form (documentID, documentScore).\n",
    "print(Retrieve(query,index,1000,'nofeedback',0.1,10,50,0.9)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20399"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pickle.load(open('AllDataPickle_e1.pk','rb'))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')+[',','.','!','``',\"''\",'?',\"'s\",';','$',':',\"'\",'_', ')', '(']\n",
    "expanded_indicators = ['futur', 'work', 'plan', 'improv', 'explor', 'approach', 'perform', 'research', 'evalu', 'extend', 'would']\n",
    "stemmer = PorterStemmer()\n",
    "docCollection = defaultdict(list)\n",
    "termFrequency = defaultdict(int)\n",
    "idf = defaultdict(int)\n",
    "docIndex = defaultdict(list)\n",
    "tfidf = defaultdict(int)\n",
    "numberofwords = 0\n",
    "docnumberofwords = defaultdict(int)\n",
    "numOfDocuments = 0\n",
    "#TF-IDF scores of the documents\n",
    "for key in data:\n",
    "    future_work_section = data[key][9]\n",
    "    if not (future_work_section == \"\"):\n",
    "        numOfDocuments = numOfDocuments + 1\n",
    "        for token in [t.lower() for t in nltk.word_tokenize(future_work_section)]:\n",
    "            if token in stopwords:\n",
    "                continue\n",
    "            if stemmer:\n",
    "                token = stemmer.stem(token)\n",
    "            if key not in docCollection:\n",
    "                docCollection[key] = []\n",
    "\n",
    "            docCollection[key].append(token)\n",
    "\n",
    "            if token not in docIndex:\n",
    "                docIndex[token] = defaultdict(int)\n",
    "\n",
    "            if key not in docIndex[token]:\n",
    "                docIndex[token][key] = 1\n",
    "\n",
    "            else:\n",
    "                docIndex[token][key] += 1\n",
    "\n",
    "            numberofwords += 1\n",
    "            docnumberofwords[key] += 1\n",
    "\n",
    "            \n",
    "for word in docIndex:\n",
    "    sumword = 0\n",
    "    for key in docIndex[word]:\n",
    "        sumword = sumword + docIndex[word][key]\n",
    "    termFrequency[word] = sumword/(numberofwords)\n",
    "    idf[word] = 6*log ((numOfDocuments)/len(docIndex[word]), 10)\n",
    "    tfidf[word] = termFrequency[word]*idf[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docCollection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04051350257329555\n",
      "3116\n",
      "1.3821031645867\n",
      "0.055993840115043186\n"
     ]
    }
   ],
   "source": [
    "print (termFrequency['work'])\n",
    "print (len(index['work']))\n",
    "print (idf['work'])\n",
    "print (tfidf['work'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['use',\n",
       " 'perform',\n",
       " 'approach',\n",
       " 'improv',\n",
       " 'work',\n",
       " 'evalu',\n",
       " 'model',\n",
       " 'system',\n",
       " 'would',\n",
       " 'futur',\n",
       " 'result',\n",
       " 'method',\n",
       " 'also',\n",
       " 'featur',\n",
       " 'research',\n",
       " 'languag',\n",
       " 'data',\n",
       " 'word',\n",
       " 'show',\n",
       " 'gener',\n",
       " 'differ',\n",
       " 'task',\n",
       " 'set',\n",
       " 'plan',\n",
       " 'inform',\n",
       " 'translat',\n",
       " 'train',\n",
       " '%',\n",
       " 'present',\n",
       " 'semant',\n",
       " 'base',\n",
       " 'explor',\n",
       " 'experi',\n",
       " 'learn',\n",
       " 'paper',\n",
       " 'extend',\n",
       " 'algorithm',\n",
       " 'two',\n",
       " 'better',\n",
       " 'test',\n",
       " 'like',\n",
       " 'compar',\n",
       " 'one',\n",
       " 'propos',\n",
       " 'sentenc',\n",
       " 'pars',\n",
       " 'et',\n",
       " 'combin',\n",
       " 'extract',\n",
       " 'text']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ item[0]  for item in sorted(termFrequency.items(),key=lambda k_v: k_v[1],reverse=True)][0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('perform', 0.013544264549265965),\n",
       " ('approach', 0.012673398131546665),\n",
       " ('improv', 0.012669353860256947),\n",
       " ('work', 0.012593860796182207),\n",
       " ('evalu', 0.009618625217379582),\n",
       " ('would', 0.007516952237156069),\n",
       " ('futur', 0.0068820016446703245),\n",
       " ('research', 0.00494075142560563),\n",
       " ('plan', 0.003901373704148074),\n",
       " ('explor', 0.003074994270615673),\n",
       " ('extend', 0.002926704323326009)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(word,score) for (word,score) in sorted(termFrequency.items(),key=lambda k_v: k_v[1],reverse=True)[0:100] if word in expanded_indicators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('creature.', 22.568860677268212),\n",
       " ('ntailment', 22.568860677268212),\n",
       " ('movementyand', 22.568860677268212),\n",
       " ('van', 22.568860677268212),\n",
       " ('stars.si', 22.568860677268212),\n",
       " ('mappings.w', 22.568860677268212),\n",
       " ('abus', 22.568860677268212),\n",
       " ('decision-mak', 22.568860677268212),\n",
       " ('dcc', 22.568860677268212),\n",
       " ('tasks.exploit', 22.568860677268212),\n",
       " ('coregress', 22.568860677268212),\n",
       " ('poems.for', 22.568860677268212),\n",
       " ('21.98', 22.568860677268212),\n",
       " ('surface-ori', 22.568860677268212),\n",
       " ('quantum', 22.568860677268212),\n",
       " ('industri', 22.568860677268212),\n",
       " ('mac', 22.568860677268212),\n",
       " ('0.0716', 22.568860677268212),\n",
       " ('dvai', 22.568860677268212),\n",
       " ('lexicalization.thu', 22.568860677268212),\n",
       " ('method.futur', 22.568860677268212),\n",
       " ('23.04', 22.568860677268212),\n",
       " ('tree-to-str', 22.568860677268212),\n",
       " ('saraclar', 22.568860677268212),\n",
       " ('sensevla-3', 22.568860677268212),\n",
       " ('delv', 22.568860677268212),\n",
       " ('multi-resolut', 22.568860677268212),\n",
       " ('-p', 22.568860677268212),\n",
       " ('pf-ccg', 22.568860677268212),\n",
       " ('correct.anoth', 22.568860677268212),\n",
       " ('fresh', 22.568860677268212),\n",
       " ('vm', 22.568860677268212),\n",
       " ('acquisi', 22.568860677268212),\n",
       " ('160.8', 22.568860677268212),\n",
       " ('ype', 22.568860677268212),\n",
       " ('24.98', 22.568860677268212),\n",
       " ('autumn', 22.568860677268212),\n",
       " ('sdrss', 22.568860677268212),\n",
       " ('0.3634', 22.568860677268212),\n",
       " ('texts.for', 22.568860677268212),\n",
       " ('ovvli', 22.568860677268212),\n",
       " ('rules.w', 22.568860677268212),\n",
       " ('observers.i', 22.568860677268212),\n",
       " ('mbdel', 22.568860677268212),\n",
       " ('paradigm.howev', 22.568860677268212),\n",
       " ('accuracy/tim', 22.568860677268212),\n",
       " ('prioritis', 22.568860677268212),\n",
       " ('30\\\\', 22.568860677268212),\n",
       " ('dagan', 22.568860677268212),\n",
       " ('them.therefor', 22.568860677268212),\n",
       " ('e2c', 22.568860677268212),\n",
       " ('23.76', 22.568860677268212),\n",
       " ('factoid', 22.568860677268212),\n",
       " ('kurdish', 22.568860677268212),\n",
       " ('high-scor', 22.568860677268212),\n",
       " ('computer-aid', 22.568860677268212),\n",
       " ('visibl', 22.568860677268212),\n",
       " ('plan.thi', 22.568860677268212),\n",
       " ('kipper', 22.568860677268212),\n",
       " ('try.moreov', 22.568860677268212),\n",
       " ('1950', 22.568860677268212),\n",
       " ('summarising.integr', 22.568860677268212),\n",
       " ('matrix-bas', 22.568860677268212),\n",
       " ('largerscal', 22.568860677268212),\n",
       " ('27.33', 22.568860677268212),\n",
       " ('vlmt', 22.568860677268212),\n",
       " ('tverski', 22.568860677268212),\n",
       " ('60', 22.568860677268212),\n",
       " ('62.73.', 22.568860677268212),\n",
       " ('models.furth', 22.568860677268212),\n",
       " ('use.w', 22.568860677268212),\n",
       " ('dasp', 22.568860677268212),\n",
       " ('rcv1', 22.568860677268212),\n",
       " ('mixed-convent', 22.568860677268212),\n",
       " ('5806', 22.568860677268212),\n",
       " ('concept-typ', 22.568860677268212),\n",
       " ('battistelli', 22.568860677268212),\n",
       " ('gemin', 22.568860677268212),\n",
       " ('0.1617', 22.568860677268212),\n",
       " ('decisions.whil', 22.568860677268212),\n",
       " ('23.20', 22.568860677268212),\n",
       " ('cv-model3', 22.568860677268212),\n",
       " ('zock', 22.568860677268212),\n",
       " ('work.oth', 22.568860677268212),\n",
       " ('eventev', 22.568860677268212),\n",
       " ('content-onli', 22.568860677268212),\n",
       " ('0.0466', 22.568860677268212),\n",
       " ('2007a', 22.568860677268212),\n",
       " ('events.our', 22.568860677268212),\n",
       " ('wordbas', 22.568860677268212),\n",
       " ('widths.for', 22.568860677268212),\n",
       " ('etymolog', 22.568860677268212),\n",
       " ('tool.w', 22.568860677268212),\n",
       " ('schwa', 22.568860677268212),\n",
       " ('dissect', 22.568860677268212),\n",
       " ('exacerb', 22.568860677268212),\n",
       " ('whadvp', 22.568860677268212),\n",
       " ('goals.onc', 22.568860677268212),\n",
       " ('ecognit', 22.568860677268212),\n",
       " ('garment', 22.568860677268212)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(idf.items(),key=lambda k_v: k_v[1],reverse=True)[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('plan', 0.07037579118942662),\n",
       " ('use', 0.05293213456402674),\n",
       " ('work', 0.049383936760795),\n",
       " ('model', 0.048664444356588656),\n",
       " ('system', 0.04700042397861948),\n",
       " ('improv', 0.0401398746472039),\n",
       " ('method', 0.039738644086697625),\n",
       " ('featur', 0.03859161667116897),\n",
       " ('also', 0.037828175741242066),\n",
       " ('investig', 0.0367591223663174),\n",
       " ('languag', 0.03574565202541156),\n",
       " ('includ', 0.03491143494268731),\n",
       " ('research', 0.034785915219210935),\n",
       " ('explor', 0.034313520153282755),\n",
       " ('evalu', 0.03264952383810066),\n",
       " ('data', 0.03237567871299978),\n",
       " ('approach', 0.03137821494528966),\n",
       " ('inform', 0.031150493844951634),\n",
       " ('gener', 0.03066298925815121),\n",
       " ('perform', 0.030561586274568946),\n",
       " ('would', 0.03030543606133991),\n",
       " ('word', 0.030114646538643743),\n",
       " ('direct', 0.028941467184662204),\n",
       " ('differ', 0.02891799834367409),\n",
       " ('task', 0.02837616561175874),\n",
       " ('extend', 0.027787520134415027),\n",
       " ('result', 0.02763279458977985),\n",
       " ('semant', 0.026808557251832787),\n",
       " ('develop', 0.02642552375127551),\n",
       " ('appli', 0.0262019792867434),\n",
       " ('like', 0.026036621486535738),\n",
       " ('experi', 0.026020994847972823),\n",
       " ('learn', 0.02553633882178992),\n",
       " ('set', 0.025349295576362212),\n",
       " ('algorithm', 0.024812885901444995),\n",
       " ('studi', 0.023693079391990213),\n",
       " ('test', 0.022980642277989877),\n",
       " ('annot', 0.022802029405862605),\n",
       " ('translat', 0.022710116687192892),\n",
       " ('extract', 0.02237412925180268),\n",
       " ('train', 0.02199955882738303),\n",
       " ('text', 0.021982687381305325),\n",
       " ('techniqu', 0.021719309670346305),\n",
       " ('addit', 0.021639519604703946),\n",
       " ('automat', 0.021561803121502254),\n",
       " ('et', 0.021523627942844136),\n",
       " ('order', 0.020982881971884405),\n",
       " ('relat', 0.020916892276694955),\n",
       " ('domain', 0.020837720307441864),\n",
       " ('al', 0.020644912623501675),\n",
       " ('&', 0.02058745994840608),\n",
       " ('sentenc', 0.020493049606779282),\n",
       " ('user', 0.020485601040372763),\n",
       " ('integr', 0.02037535193276819),\n",
       " ('structur', 0.02026361381386615),\n",
       " ('well', 0.02004100403050482),\n",
       " ('combin', 0.020018017994708603),\n",
       " ('corpu', 0.019741070587186278),\n",
       " ('base', 0.019616390834884947),\n",
       " ('type', 0.019572573003061467),\n",
       " ('new', 0.019507208973716026),\n",
       " ('possibl', 0.019320334769128925),\n",
       " ('one', 0.019296023822838394),\n",
       " ('interest', 0.01890511114792258),\n",
       " ('analysi', 0.01880343465495132),\n",
       " ('better', 0.018753619054429637),\n",
       " ('applic', 0.01843206873314602),\n",
       " ('intend', 0.018283423017556134),\n",
       " ('futur', 0.018241954112738275),\n",
       " ('incorpor', 0.018107973788318157),\n",
       " ('propos', 0.01799271843149942),\n",
       " ('conclus', 0.017962617373463767),\n",
       " ('current', 0.017941547536152777),\n",
       " ('problem', 0.017842546240869405),\n",
       " ('effect', 0.01782029010134706),\n",
       " ('may', 0.01768127092440876),\n",
       " ('error', 0.017378159597526928),\n",
       " ('select', 0.017235422982381385),\n",
       " ('hope', 0.017208701435839125),\n",
       " ('could', 0.017180988834641486),\n",
       " ('make', 0.017180988834641486),\n",
       " ('two', 0.01716438486490344),\n",
       " ('way', 0.017017519336865936),\n",
       " ('pars', 0.016941460289620406),\n",
       " ('consid', 0.016742397606044693),\n",
       " ('process', 0.016672029772879404),\n",
       " ('address', 0.016497751138415343),\n",
       " ('focu', 0.016387715866491518),\n",
       " ('present', 0.016076676449422414),\n",
       " ('rule', 0.015962374576226023),\n",
       " ('similar', 0.015784257029857536),\n",
       " ('linguist', 0.015748090211728637),\n",
       " ('question', 0.015725084516718082),\n",
       " ('syntact', 0.015641788479778457),\n",
       " ('provid', 0.015641788479778457),\n",
       " ('knowledg', 0.01547568338504202),\n",
       " ('number', 0.01545266711114151),\n",
       " ('import', 0.015317606335119834),\n",
       " ('compar', 0.015090577931815764),\n",
       " ('corpora', 0.014979764375800517),\n",
       " ('topic', 0.014874402295619376),\n",
       " ('sever', 0.014807640965076205),\n",
       " ('context', 0.014664639637812674),\n",
       " ('lexic', 0.014593055923219588),\n",
       " ('machin', 0.01453310192327596),\n",
       " ('detect', 0.014449419372887393),\n",
       " ('larger', 0.0142758053034617),\n",
       " ('dialogu', 0.01407969918051915),\n",
       " ('issu', 0.013886288875226891),\n",
       " ('discours', 0.013793616472820144),\n",
       " ('speech', 0.013757889437416203),\n",
       " ('measur', 0.0137412406997164),\n",
       " ('classifi', 0.013724513640318762),\n",
       " ('align', 0.013698141974081384),\n",
       " ('paper', 0.013538793835798413),\n",
       " ('cluster', 0.01345517951849065),\n",
       " ('need', 0.013406284684862138),\n",
       " ('exampl', 0.013298509047507026),\n",
       " ('area', 0.013284047795703389),\n",
       " ('examin', 0.013197787745081938),\n",
       " ('adapt', 0.013173044602811719),\n",
       " ('near', 0.013089474020145049),\n",
       " ('pattern', 0.013024135334087337),\n",
       " ('resourc', 0.012865082517792366),\n",
       " ('framework', 0.012826426492740756),\n",
       " ('complex', 0.01271453791529371),\n",
       " ('avail', 0.012680227441353236),\n",
       " ('implement', 0.012651364074117625),\n",
       " ('phrase', 0.01258733562631708),\n",
       " ('strategi', 0.012546045767241283),\n",
       " ('recognit', 0.012502159228035865),\n",
       " ('parser', 0.012428115565888407),\n",
       " ('whether', 0.012424497500059752),\n",
       " ('compon', 0.012409895722366452),\n",
       " ('term', 0.012402227749459475),\n",
       " ('construct', 0.01239820758029032),\n",
       " ('e.g.', 0.012245124338156077),\n",
       " ('natur', 0.012209008686910716),\n",
       " ('accuraci', 0.012199781820276985),\n",
       " ('part', 0.012124565934173069),\n",
       " ('event', 0.012093458762935624),\n",
       " ('classif', 0.012078003613116927),\n",
       " ('pair', 0.012001934213648013),\n",
       " ('collect', 0.011901789310868756),\n",
       " ('express', 0.011884122354304487),\n",
       " ('identifi', 0.01186303315236412),\n",
       " ('segment', 0.011808806581877595),\n",
       " ('depend', 0.011779357030042369),\n",
       " ('document', 0.01170087502904172),\n",
       " ('tri', 0.011677159871280426),\n",
       " ('specif', 0.011668068422160956),\n",
       " ('apo', 0.011631526973664784),\n",
       " ('predict', 0.01162733183650809),\n",
       " ('find', 0.011619461050805038),\n",
       " ('mani', 0.011422836129212625),\n",
       " ('represent', 0.011410384078485936),\n",
       " ('suggest', 0.011322792804071733),\n",
       " ('function', 0.011277213467643496),\n",
       " ('allow', 0.011248805329709215),\n",
       " ('tag', 0.011239888602856855),\n",
       " ('continu', 0.011231479958877607),\n",
       " ('determin', 0.01120680755941567),\n",
       " ('build', 0.011173437415704165),\n",
       " ('level', 0.011169894683211857),\n",
       " ('grammar', 0.011162345773018277),\n",
       " ('take', 0.011157927478939459),\n",
       " ('increas', 0.011148077783575181),\n",
       " ('achiev', 0.011108542047101272),\n",
       " ('extens', 0.01103101841988129),\n",
       " ('sourc', 0.01103101841988129),\n",
       " ('see', 0.010971962020957135),\n",
       " ('sens', 0.010969891535552443),\n",
       " ('comput', 0.010921364734598643),\n",
       " ('qualiti', 0.010896410041761086),\n",
       " ('refer', 0.010826361272319656),\n",
       " ('summar', 0.010790705785224322),\n",
       " ('time', 0.010763622136634106),\n",
       " ('infer', 0.010754529817415714),\n",
       " ('believ', 0.010749741122609444),\n",
       " ('discuss', 0.01073625685774104),\n",
       " ('follow', 0.01066824527663319),\n",
       " ('first', 0.010595280538108645),\n",
       " ('sophist', 0.010592290042518717),\n",
       " ('constraint', 0.010557781459705703),\n",
       " ('tree', 0.010518707956104744),\n",
       " ('optim', 0.010487796273621992),\n",
       " ('output', 0.010487796273621992),\n",
       " ('score', 0.010461801628253834),\n",
       " ('label', 0.010400353049135119),\n",
       " ('statist', 0.010280709020787216),\n",
       " ('action', 0.010276397617509663),\n",
       " ('verb', 0.010265687552987728),\n",
       " ('handl', 0.010255858493247588),\n",
       " ('goal', 0.010213548370112882),\n",
       " ('expect', 0.010183433421376701),\n",
       " ('paraphras', 0.010175680201513989),\n",
       " ('5', 0.01011670705688598),\n",
       " ('search', 0.010103847466956199),\n",
       " ('aim', 0.010065612020706593),\n",
       " ('look', 0.010059887238335072),\n",
       " ('larg', 0.009973587158571048),\n",
       " ('correct', 0.009956478991832223),\n",
       " ('human', 0.009945448802011253),\n",
       " ('exploit', 0.009925950044677955),\n",
       " ('involv', 0.00990343529525374),\n",
       " ('case', 0.009885922639542612),\n",
       " ('multipl', 0.009811089204188609),\n",
       " ('name', 0.00975697193859774),\n",
       " ('quot', 0.00966942163413296),\n",
       " ('describ', 0.00964479012661643),\n",
       " ('enhanc', 0.00962058261769951),\n",
       " ('summari', 0.009570848851516852),\n",
       " ('analyz', 0.009551228033939405),\n",
       " ('avenu', 0.009502003313735132),\n",
       " ('english', 0.009479509128431126),\n",
       " ('weight', 0.009407552779748),\n",
       " ('variou', 0.00938204309417278),\n",
       " ('queri', 0.009339039774111688),\n",
       " ('obtain', 0.009286307960558772),\n",
       " ('refin', 0.009286049758463142),\n",
       " ('support', 0.009245936734187946),\n",
       " ('expand', 0.009189320073479152),\n",
       " ('help', 0.009165413601853507),\n",
       " ('produc', 0.009120458400447345),\n",
       " ('morpholog', 0.009120458400447345),\n",
       " ('sinc', 0.009094710840500383),\n",
       " ('exist', 0.00909259038849516),\n",
       " ('class', 0.00903384407957907),\n",
       " ('1', 0.008973486662478637),\n",
       " ('paramet', 0.008970404801814071),\n",
       " ('deriv', 0.008867986418891105),\n",
       " ('add', 0.008858126064701767),\n",
       " ('answer', 0.008851876172026906),\n",
       " ('precis', 0.008847511364947916),\n",
       " ('estim', 0.008825489071620417),\n",
       " ('size', 0.008823197120745462),\n",
       " ('dataset', 0.008723916730862678),\n",
       " ('content', 0.008702713748145224),\n",
       " ('retriev', 0.008676442982172267),\n",
       " ('scheme', 0.008649424686820981),\n",
       " ('entiti', 0.008624909774538133),\n",
       " ('understand', 0.008575554110286545),\n",
       " ('altern', 0.008575554110286545),\n",
       " ('metric', 0.008525645896070343),\n",
       " ('tool', 0.008499634682730448),\n",
       " ('detail', 0.008474959625674268),\n",
       " ('requir', 0.008426510478674177),\n",
       " ('particular', 0.008426510478674177),\n",
       " ('instanc', 0.008416817328525226),\n",
       " ('relev', 0.008401540582665002),\n",
       " ('ad', 0.008399638980580677),\n",
       " ('distribut', 0.008399130710419226),\n",
       " ('aspect', 0.00837921499312613),\n",
       " ('6', 0.008375254218313394),\n",
       " ('potenti', 0.00832737506127801),\n",
       " ('howev', 0.008303866419587306),\n",
       " ('conduct', 0.008299643278430907),\n",
       " ('design', 0.008275548810952521),\n",
       " ('section', 0.00822181315107758),\n",
       " ('introduc', 0.008199647576281138),\n",
       " ('nlp', 0.008199647576281138),\n",
       " ('web', 0.008170838696090305),\n",
       " ('impact', 0.00809554767269323),\n",
       " ('interact', 0.008071109750857923),\n",
       " ('chines', 0.008069284341588807),\n",
       " ('therefor', 0.008046987165853805),\n",
       " ('given', 0.008018805418952208),\n",
       " ('best', 0.008017202583011022),\n",
       " ('belief', 0.008006315595659022),\n",
       " ('show', 0.007994353326784566),\n",
       " ('standard', 0.007994353326784566),\n",
       " ('input', 0.007965831978235105),\n",
       " ('thu', 0.007922882234750147),\n",
       " ('point', 0.007917301552889522),\n",
       " ('effici', 0.007889251522746403),\n",
       " ('role', 0.007889251522746403),\n",
       " ('remain', 0.007869332007086475),\n",
       " ('e.g', 0.007845812486707461),\n",
       " ('lexicon', 0.007840457904191831),\n",
       " ('[', 0.00782362535039544),\n",
       " ('mt', 0.007812789092804617),\n",
       " ('form', 0.007810478975317859),\n",
       " ('final', 0.007791964634967234),\n",
       " ('version', 0.0077622967612857915),\n",
       " ('activ', 0.007758745200061158),\n",
       " ('step', 0.007738133113992349),\n",
       " ('target', 0.007738133113992349),\n",
       " ('disambigu', 0.0077337090862422435),\n",
       " ('kind', 0.007660161277584662),\n",
       " ('rank', 0.007602199535976049),\n",
       " ('contribut', 0.00757692654944262),\n",
       " ('categori', 0.007575135595672704),\n",
       " ('formal', 0.007554191699486388),\n",
       " ('open', 0.007552022524820293),\n",
       " ('2008', 0.007549580284566632),\n",
       " ('modul', 0.007549580284566632),\n",
       " ('even', 0.007527476843942449),\n",
       " ('anoth', 0.007503279340510315),\n",
       " ('parallel', 0.007498059816305145),\n",
       " (']', 0.007474246459868257),\n",
       " ('reduc', 0.007448570161466592),\n",
       " ('%', 0.007434964047158708),\n",
       " ('appropri', 0.007424360722792554),\n",
       " ('promis', 0.0074004946920101745),\n",
       " ('mean', 0.007390476168869232),\n",
       " ('next', 0.007390476168869232),\n",
       " ('2', 0.007364715162459573),\n",
       " ('leav', 0.007345117798112889),\n",
       " ('much', 0.007297710043510033),\n",
       " ('robust', 0.007297710043510033),\n",
       " ('us', 0.007289780376963335),\n",
       " ('line', 0.007241665434759186),\n",
       " ('util', 0.007234505659516486),\n",
       " ('defin', 0.007154294729246442),\n",
       " ('sentiment', 0.0071540574667724455),\n",
       " ('commun', 0.007150131494805262),\n",
       " ('argument', 0.007073036335720826),\n",
       " ('want', 0.007069335008155583),\n",
       " ('indic', 0.007069335008155583),\n",
       " ('2007', 0.007069335008155583),\n",
       " ('within', 0.007024809843298616),\n",
       " ('relationship', 0.007014606578094503),\n",
       " ('account', 0.0069438742960333125),\n",
       " ('utter', 0.00689032095519105),\n",
       " ('carri', 0.006862585013950002),\n",
       " ('employ', 0.006829976353246818),\n",
       " ('2010', 0.006829976353246818),\n",
       " ('identif', 0.006829976353246818),\n",
       " ('decis', 0.006798514331015934),\n",
       " ('repres', 0.006769715892369855),\n",
       " ('reason', 0.00676919040191273),\n",
       " ('effort', 0.006748001598693966),\n",
       " ('might', 0.006733453862820181),\n",
       " ('limit', 0.006698923351094336),\n",
       " ('dialog', 0.006693022474462395),\n",
       " ('subject', 0.006690855505259372),\n",
       " ('rather', 0.006665657606496542),\n",
       " ('simpl', 0.006665657606496542),\n",
       " ('lead', 0.00665142855198231),\n",
       " ('decod', 0.006633853687255331),\n",
       " ('abl', 0.006616539592207855),\n",
       " ('agent', 0.006565529564255943),\n",
       " ('ontolog', 0.006550829421205866),\n",
       " ('creat', 0.006499838136401518),\n",
       " ('three', 0.006486259117726261),\n",
       " ('pursu', 0.006486259117726261),\n",
       " ('shown', 0.00646742047315121),\n",
       " ('comparison', 0.00645063639338375),\n",
       " ('link', 0.006441648930852436),\n",
       " ('object', 0.006441648930852436),\n",
       " ('attempt', 0.006409939179246998),\n",
       " ('mention', 0.006391507500794826),\n",
       " ('rang', 0.006343125786827355),\n",
       " ('list', 0.006343125786827355),\n",
       " ('chang', 0.006332468440499005),\n",
       " ('resolut', 0.006332468440499005),\n",
       " ('full', 0.006319557052745142),\n",
       " ('deal', 0.006319557052745142),\n",
       " ('still', 0.006319557052745142),\n",
       " ('run', 0.0062994229865013605),\n",
       " ('graph', 0.006297689375726296),\n",
       " ('recal', 0.006283176865188134),\n",
       " ('factor', 0.006273558086246606),\n",
       " ('scale', 0.006259187408145865),\n",
       " ('challeng', 0.006259187408145865),\n",
       " ('assess', 0.006248185880840998),\n",
       " ('particip', 0.006239258238905622),\n",
       " ('without', 0.006223287950145573),\n",
       " ('match', 0.006214821147093638),\n",
       " ('tempor', 0.006212878954725791),\n",
       " ('go', 0.006212878954725791),\n",
       " ('report', 0.006198846888091047),\n",
       " ('discrimin', 0.006198846888091047),\n",
       " ('idea', 0.006198846888091047),\n",
       " ('start', 0.0061896103495784),\n",
       " ('2009', 0.006188906793755724),\n",
       " ('noun', 0.0061634956636808765),\n",
       " ('complet', 0.006138568584685894),\n",
       " ('reorder', 0.006097825640749387),\n",
       " ('manual', 0.0060900951882999765),\n",
       " ('success', 0.0060900951882999765),\n",
       " ('toward', 0.00606651559397475),\n",
       " ('contextu', 0.0060534332411151465),\n",
       " ('individu', 0.006028951288530788),\n",
       " ('dictionari', 0.006012376121127236),\n",
       " ('tabl', 0.005932443433742676),\n",
       " ('joint', 0.005919333992375683),\n",
       " ('2006', 0.005906905894161385),\n",
       " ('boundari', 0.005896438232094914),\n",
       " ('good', 0.005869605363546718),\n",
       " ('project', 0.0058573582155188085),\n",
       " ('made', 0.0058573582155188085),\n",
       " ('respons', 0.005846380243096112),\n",
       " ('ambigu', 0.0058205105387664),\n",
       " ('wordnet', 0.005795454839554567),\n",
       " ('directli', 0.005795454839554567),\n",
       " ('left', 0.005746842022773172),\n",
       " ('baselin', 0.005746842022773172),\n",
       " ('accur', 0.0057232459734179566),\n",
       " ('instead', 0.005684003784947748),\n",
       " ('po', 0.005672052944459656),\n",
       " ('coher', 0.005665205360248054),\n",
       " ('benefit', 0.0056599264018174205),\n",
       " ('interpret', 0.005621244004759256),\n",
       " ('hierarch', 0.005621244004759256),\n",
       " ('captur', 0.005621244004759256),\n",
       " ('contain', 0.005596644748813846),\n",
       " ('consist', 0.005596644748813846),\n",
       " ('coverag', 0.005596644748813846),\n",
       " ('must', 0.0055772862485778665),\n",
       " ('corefer', 0.005558611885570463),\n",
       " ('speaker', 0.005551689060408587),\n",
       " ('smt', 0.005549588924324624),\n",
       " ('main', 0.005548947452762177),\n",
       " ('although', 0.005548947452762177),\n",
       " ('probabl', 0.005533444870966742),\n",
       " ('3', 0.0055088191246640715),\n",
       " ('observ', 0.0055088191246640715),\n",
       " ('condit', 0.0054961652733611305),\n",
       " ('supervis', 0.005470378283897586),\n",
       " ('cost', 0.005463359008597542),\n",
       " ('focus', 0.005461101675734111),\n",
       " ('concept', 0.005461092785065828),\n",
       " ('valu', 0.0054451708266812695),\n",
       " ('among', 0.0054451708266812695),\n",
       " ('adopt', 0.005431000167791009),\n",
       " ('7', 0.0053963942445688865),\n",
       " ('empir', 0.0053963942445688865),\n",
       " ('autom', 0.0053963942445688865),\n",
       " ('especi', 0.0053963942445688865),\n",
       " ('methodolog', 0.0053963942445688865),\n",
       " ('asr', 0.005381661830166108),\n",
       " ('initi', 0.0053727789588612915),\n",
       " ('opinion', 0.005369124713047449),\n",
       " ('acquisit', 0.00535641206964972),\n",
       " ('figur', 0.005354721069665319),\n",
       " ('descript', 0.005331729767792077),\n",
       " ('real', 0.005331729767792077),\n",
       " ('analys', 0.005331729767792077),\n",
       " ('normal', 0.005318356052477765),\n",
       " ('beyond', 0.005307589978274222),\n",
       " ('unsupervis', 0.005307589978274222),\n",
       " ('\\\\', 0.005302927724975954),\n",
       " ('definit', 0.0052839693644737016),\n",
       " ('along', 0.0052839693644737016),\n",
       " ('l', 0.005253356909880381),\n",
       " ('singl', 0.005242445855401854),\n",
       " ('share', 0.005220543052659873),\n",
       " ('amount', 0.005218288708902884),\n",
       " ('feedback', 0.005177399128938159),\n",
       " ('space', 0.005177399128938159),\n",
       " ('posit', 0.005177399128938159),\n",
       " ('cue', 0.005165252719921112),\n",
       " ('spoken', 0.00515265494377606),\n",
       " ('high', 0.00515265494377606),\n",
       " ('concern', 0.00515265494377606),\n",
       " ('local', 0.00515265494377606),\n",
       " ('lattic', 0.00515265494377606),\n",
       " ('realiz', 0.005138544441159427),\n",
       " ('network', 0.005138544441159427),\n",
       " ('valid', 0.005128479641153987),\n",
       " ('kernel', 0.005102189653877504),\n",
       " ('give', 0.005102189653877504),\n",
       " ('oper', 0.005099135074691039),\n",
       " ('move', 0.005087123180630906),\n",
       " ('articl', 0.005087123180630906),\n",
       " ('heurist', 0.005047860612650177),\n",
       " ('sequenc', 0.005047860612650177),\n",
       " ('state', 0.005039633581004201),\n",
       " ('properti', 0.005038151500581037),\n",
       " ('product', 0.005021759340223985),\n",
       " ('signific', 0.005014513426906121),\n",
       " ('predic', 0.004983534080531517),\n",
       " ('accord', 0.004971506744707476),\n",
       " ('engin', 0.004971506744707476),\n",
       " ('sampl', 0.004956642698105805),\n",
       " ('previou', 0.004947292500985352),\n",
       " ('second', 0.004947292500985352),\n",
       " ('fulli', 0.004947292500985352),\n",
       " ('dynam', 0.004930468505379243),\n",
       " ('wsd', 0.004930468505379243),\n",
       " ('power', 0.004880125467505634),\n",
       " ('enabl', 0.004855890308784046),\n",
       " ('filter', 0.004838627395769952),\n",
       " ('map', 0.004838627395769952),\n",
       " ('experiment', 0.004832239187008949),\n",
       " ('advantag', 0.004832239187008949),\n",
       " ('alreadi', 0.004832239187008949),\n",
       " ('associ', 0.004832239187008949),\n",
       " ('organ', 0.004827555704703119),\n",
       " ('treebank', 0.004813076398108309),\n",
       " ('rate', 0.004813076398108309),\n",
       " ('tagger', 0.00479965102952781),\n",
       " ('candid', 0.00479965102952781),\n",
       " ('cover', 0.004788189138353102),\n",
       " ('rel', 0.004763932003993595),\n",
       " ('affect', 0.0047206120934341),\n",
       " ('respect', 0.0047206120934341),\n",
       " ('group', 0.0047206120934341),\n",
       " ('phenomena', 0.004695684290837374),\n",
       " ('act', 0.004679659753789616),\n",
       " ('n-gram', 0.004679659753789616),\n",
       " ('collabor', 0.00467859513725751),\n",
       " ('bilingu', 0.004653241417974456),\n",
       " ('2005', 0.004653241417974456),\n",
       " ('deeper', 0.0046477385404815556),\n",
       " ('richer', 0.0046477385404815556),\n",
       " ('2004', 0.004627567360493551),\n",
       " ('discov', 0.004627567360493551),\n",
       " ('2003', 0.004627567360493551),\n",
       " ('correl', 0.004602596791098247),\n",
       " ('influenc', 0.00457829218356644),\n",
       " ('global', 0.00457829218356644),\n",
       " ('practic', 0.00457829218356644),\n",
       " ('found', 0.00457829218356644),\n",
       " ('convers', 0.004559668478051421),\n",
       " ('prefer', 0.004547897249624768),\n",
       " ('necessari', 0.004533927535462291),\n",
       " ('bootstrap', 0.004533927535462291),\n",
       " ('simul', 0.0045136170617652025),\n",
       " ('regard', 0.004508911787147562),\n",
       " ('recogn', 0.004508911787147562),\n",
       " ('seem', 0.004508911787147562),\n",
       " ('tune', 0.004508911787147562),\n",
       " ('mine', 0.004508911787147562),\n",
       " ('overal', 0.004508911787147562),\n",
       " ('technolog', 0.004484581488762396),\n",
       " ('across', 0.004484581488762396),\n",
       " ('think', 0.004483022290882593),\n",
       " ('higher', 0.004460900076295506),\n",
       " ('textual', 0.004460900076295506),\n",
       " ('demonstr', 0.004460900076295506),\n",
       " ('get', 0.004453501245071933),\n",
       " ('news', 0.004439677202313225),\n",
       " ('correspond', 0.004439677202313225),\n",
       " ('come', 0.004419106437479961),\n",
       " ('scope', 0.004414613652950125),\n",
       " ('basi', 0.004397396227297168),\n",
       " ('connect', 0.004397396227297168),\n",
       " ('arab', 0.004397396227297168),\n",
       " ('immedi', 0.004390256213801574),\n",
       " ('grammat', 0.004390256213801574),\n",
       " ('interfac', 0.004390256213801574),\n",
       " ('multilingu', 0.0043706872068780345),\n",
       " ('prosod', 0.0043706872068780345),\n",
       " ('.we', 0.004366566186426542),\n",
       " ('etc', 0.004366566186426542),\n",
       " ('flexibl', 0.004366566186426542),\n",
       " ('suitabl', 0.004366566186426542),\n",
       " ('unit', 0.004358493893913632),\n",
       " ('motiv', 0.004344800134232807),\n",
       " ('entail', 0.00431968592657503),\n",
       " ('assign', 0.00431968592657503),\n",
       " ('increment', 0.004302064965861267),\n",
       " ('emot', 0.004295411195134467),\n",
       " ('independ', 0.00429529977043796),\n",
       " ('mechan', 0.00429529977043796),\n",
       " ('procedur', 0.00429529977043796),\n",
       " ('genr', 0.004275246332094468),\n",
       " ('variat', 0.004275246332094468),\n",
       " ('encourag', 0.004275246332094468),\n",
       " ('imag', 0.004262860558333802),\n",
       " ('2002', 0.0042492792289092),\n",
       " ('control', 0.004233965496944671),\n",
       " ('prove', 0.004224111241615229),\n",
       " ('releas', 0.004199694650836834),\n",
       " ('remov', 0.004199694650836834),\n",
       " ('capabl', 0.004199694650836834),\n",
       " ('concentr', 0.004199694650836834),\n",
       " ('4', 0.004199694650836834),\n",
       " ('o', 0.004179148823979517),\n",
       " ('varieti', 0.004175985887925794),\n",
       " ('phase', 0.004166586069623964),\n",
       " ('social', 0.004127871250940366),\n",
       " ('close', 0.004127871250940366),\n",
       " ('modifi', 0.004127871250940366),\n",
       " ('transliter', 0.0041094370999757105),\n",
       " ('edit', 0.0041094370999757105),\n",
       " ('evid', 0.0041094370999757105),\n",
       " ('small', 0.004103422348997651),\n",
       " ('attribut', 0.004103422348997651),\n",
       " ('databas', 0.004103422348997651),\n",
       " ('read', 0.004085671113013926),\n",
       " ('architectur', 0.0040823761413159385),\n",
       " ('wikipedia', 0.0040823761413159385),\n",
       " ('separ', 0.0040823761413159385),\n",
       " ('field', 0.004079703375098639),\n",
       " ('far', 0.004079703375098639),\n",
       " ('encod', 0.0040696547333604),\n",
       " ('difficult', 0.004035083243914195),\n",
       " ('path', 0.004030946541689071),\n",
       " ('induct', 0.004006463272971532),\n",
       " ('intent', 0.004002881438964399),\n",
       " ('frequenc', 0.003984908703006749),\n",
       " ('scalabl', 0.003982733456380073),\n",
       " ('gain', 0.003982733456380073),\n",
       " ('index', 0.003958667773397273),\n",
       " ('principl', 0.003933316540216016),\n",
       " ('acquir', 0.003933316540216016),\n",
       " ('becom', 0.003933316540216016),\n",
       " ('...', 0.0038879266893577604),\n",
       " ('establish', 0.003885055295002697),\n",
       " ('theoret', 0.003885055295002697),\n",
       " ('solv', 0.003885055295002697),\n",
       " ('actual', 0.003885055295002697),\n",
       " ('wider', 0.003885055295002697),\n",
       " ('review', 0.0038603803060377885),\n",
       " ('advanc', 0.0038603803060377885),\n",
       " ('done', 0.003834959405478609),\n",
       " ('frame', 0.003834959405478609),\n",
       " ('regular', 0.0038062811848215026),\n",
       " ('prune', 0.0037878055178399666),\n",
       " ('extent', 0.0037866467512836723),\n",
       " ('purpos', 0.0037613475514710016),\n",
       " ('agreement', 0.003744631023547341),\n",
       " ('confid', 0.0037358519090688273),\n",
       " ('stage', 0.0037112510375599435),\n",
       " ('fact', 0.0037112510375599435),\n",
       " ('scenario', 0.0037112510375599435),\n",
       " ('situat', 0.0036881246021078624),\n",
       " ('major', 0.0036874842564525146),\n",
       " ('special', 0.0036874842564525146),\n",
       " ('abil', 0.0036874842564525146),\n",
       " ('stori', 0.0036771040017125342),\n",
       " ('claus', 0.00367503010948283),\n",
       " ('vector', 0.003661545333911968),\n",
       " ('author', 0.003661545333911968),\n",
       " ('charact', 0.003661545333911968),\n",
       " ('cours', 0.003661545333911968),\n",
       " ('crf', 0.0036445913170837893),\n",
       " ('planner', 0.0036410400371229513),\n",
       " ('restrict', 0.003635969299755302),\n",
       " ('behavior', 0.003635969299755302),\n",
       " ('n-best', 0.003615505815838812),\n",
       " ('svm', 0.0036113235120998665),\n",
       " ('semi-supervis', 0.0036113235120998665),\n",
       " ('distinct', 0.0036113235120998665),\n",
       " ('togeth', 0.0036113235120998665),\n",
       " ('length', 0.0035876583774792845),\n",
       " ('basic', 0.003587542669641279),\n",
       " ('tackl', 0.003587542669641279),\n",
       " ('probabilist', 0.003587542669641279),\n",
       " ('preliminari', 0.003587542669641279),\n",
       " ('assumpt', 0.003587542669641279),\n",
       " ('8', 0.003587542669641279),\n",
       " ('resolv', 0.003587542669641279),\n",
       " ('element', 0.00356094789169035),\n",
       " ('certain', 0.00356094789169035),\n",
       " ('program', 0.00356094789169035),\n",
       " ('turn', 0.0035352851499839692),\n",
       " ('person', 0.0035352851499839692),\n",
       " ('rerank', 0.003514427341473654),\n",
       " ('modal', 0.003514427341473654),\n",
       " ('transfer', 0.003514427341473654),\n",
       " ('enrich', 0.003510591048039602),\n",
       " ('choic', 0.003510591048039602),\n",
       " ('gold', 0.003510591048039602),\n",
       " ('surfac', 0.003506186702414694),\n",
       " ('onlin', 0.0034867951151309057),\n",
       " ('end', 0.0034867951151309057),\n",
       " ('solut', 0.0034867951151309057),\n",
       " ('verifi', 0.0034867951151309057),\n",
       " ('lie', 0.0034867951151309057),\n",
       " ('fragment', 0.0034733365844632864),\n",
       " ('origin', 0.0034595277211407383),\n",
       " ('composit', 0.0034595277211407383),\n",
       " ('2011', 0.0034595277211407383),\n",
       " ('japanes', 0.0034595277211407383),\n",
       " ('characterist', 0.0034337711812728374),\n",
       " ('transform', 0.0034337711812728374),\n",
       " ('distanc', 0.0034337711812728374),\n",
       " ('visual', 0.0034337711812728374),\n",
       " ('speed', 0.0034337711812728374),\n",
       " ('colloc', 0.003412527958805485),\n",
       " ('wish', 0.0034090249660559705),\n",
       " ('less', 0.0034090249660559705),\n",
       " ('environ', 0.0034090249660559705),\n",
       " ('work.w', 0.0034090249660559705),\n",
       " ('induc', 0.0034090249660559705),\n",
       " ('whole', 0.0034090249660559705),\n",
       " ('page', 0.0034047259275116057),\n",
       " ('unseen', 0.003385212796323902),\n",
       " ('iter', 0.003385212796323902),\n",
       " ('averag', 0.0033842633658635185),\n",
       " ('1998', 0.0033842633658635185),\n",
       " ('learner', 0.003357255400421754),\n",
       " ('ion', 0.003339746715830083),\n",
       " ('dialect', 0.003339746715830083),\n",
       " ('either', 0.0033313970648021925),\n",
       " ('rich', 0.0033313970648021925),\n",
       " ('node', 0.0033313970648021925),\n",
       " ('variabl', 0.003306594470855325),\n",
       " ('hypothesi', 0.003306594470855325),\n",
       " ('2012', 0.003306594470855325),\n",
       " ('fusion', 0.003306594470855325),\n",
       " ('manag', 0.003306594470855325),\n",
       " ('common', 0.0032827647821279714),\n",
       " ('elabor', 0.0032827647821279714),\n",
       " ('guid', 0.0032827647821279714),\n",
       " ('insight', 0.0032827647821279714),\n",
       " ('progress', 0.0032827647821279714),\n",
       " ('yet', 0.0032827647821279714),\n",
       " ('longer', 0.0032827647821279714),\n",
       " ('right', 0.003276532741676161),\n",
       " ('easi', 0.003276532741676161),\n",
       " ('syntax', 0.0032540993902533833),\n",
       " ('appear', 0.0032540993902533833),\n",
       " ('underli', 0.0032364800329981788),\n",
       " ('unlabel', 0.0032281301927132248),\n",
       " ('place', 0.0032281301927132248),\n",
       " ('divers', 0.0032281301927132248),\n",
       " ('partial', 0.0032281301927132248),\n",
       " ('abstract', 0.0032281301927132248),\n",
       " ('chain', 0.0032281301927132248),\n",
       " ('side', 0.0032281301927132248),\n",
       " ('format', 0.0032061568471968794),\n",
       " ('criteria', 0.0032032664084636463),\n",
       " ('character', 0.0032032664084636463),\n",
       " ('hypothes', 0.0031794177604378125),\n",
       " ('prior', 0.0031794177604378125),\n",
       " ('avoid', 0.0031794177604378125),\n",
       " ('reliabl', 0.0031794177604378125),\n",
       " ('least', 0.0031794177604378125),\n",
       " ('expans', 0.0031794177604378125),\n",
       " ('vari', 0.0031794177604378125),\n",
       " ('rhetor', 0.0031773893969833885),\n",
       " ('synonym', 0.00315002580812814),\n",
       " ('item', 0.00315002580812814),\n",
       " ('via', 0.0031239354146432477),\n",
       " ('templat', 0.0031239354146432477),\n",
       " ('smooth', 0.0031239354146432477),\n",
       " ('large-scal', 0.0031239354146432477),\n",
       " ('i.e.', 0.0030990049850046957),\n",
       " ('ii', 0.0030751357521251006),\n",
       " ('long', 0.0030751357521251006),\n",
       " ('approxim', 0.0030751357521251006),\n",
       " ('offer', 0.0030751357521251006),\n",
       " ('variant', 0.0030751357521251006),\n",
       " ('consider', 0.0030751357521251006),\n",
       " ('serv', 0.0030751357521251006),\n",
       " ('hand', 0.0030725669785636764),\n",
       " ('preposit', 0.0030725669785636764),\n",
       " ('caus', 0.003044998172109081),\n",
       " ('knowref', 0.0030359517717026864),\n",
       " ('negat', 0.003027326265284271),\n",
       " ('qa', 0.0030187747327894677),\n",
       " ('due', 0.002993771439033113),\n",
       " ('track', 0.002993771439033113),\n",
       " ('hierarchi', 0.002993771439033113),\n",
       " ('begin', 0.002991616851095625),\n",
       " ('locat', 0.002969879777296167),\n",
       " ('realist', 0.002969879777296167),\n",
       " ('known', 0.002969879777296167),\n",
       " ('distinguish', 0.002969879777296167),\n",
       " ('reflect', 0.002969879777296167),\n",
       " ('explicitli', 0.002969879777296167),\n",
       " ('besid', 0.002969879777296167),\n",
       " ('leverag', 0.002969879777296167),\n",
       " ('deep', 0.002969879777296167),\n",
       " ('ne', 0.0029667733635816637),\n",
       " ('anaphora', 0.0029667733635816637),\n",
       " ('attach', 0.002938977109930473),\n",
       " ('peopl', 0.002938977109930473),\n",
       " ('implicit', 0.002938977109930473),\n",
       " ('pivot', 0.002927234739448086),\n",
       " ('m', 0.002927234739448086),\n",
       " ('core', 0.0029213919681244085),\n",
       " ('unknown', 0.002912606947234773),\n",
       " ('cross-lingu', 0.002912606947234773),\n",
       " ('theori', 0.002912606947234773),\n",
       " ('comprehens', 0.002887523657450795),\n",
       " ('hybrid', 0.002887523657450795),\n",
       " ('2000', 0.002887523657450795),\n",
       " ('prototyp', 0.002887523657450795),\n",
       " ('linear', 0.002887523657450795),\n",
       " ('notion', 0.002887523657450795),\n",
       " ('view', 0.002887523657450795),\n",
       " ('2001', 0.002887523657450795),\n",
       " ('low', 0.002887523657450795),\n",
       " ('p', 0.0028699708253400024),\n",
       " ('though', 0.0028636074634229773),\n",
       " ('greater', 0.0028636074634229773),\n",
       " ('access', 0.0028636074634229773),\n",
       " ('5.', 0.0028636074634229773),\n",
       " ('constitu', 0.002859969779109749),\n",
       " ('per', 0.002831920028873406),\n",
       " ('lesson', 0.00282319073849496),\n",
       " ('accept', 0.002814523166624597),\n",
       " ('tens', 0.0028053872412972694),\n",
       " ('random', 0.0028053872412972694),\n",
       " ('spars', 0.0028053872412972694),\n",
       " ('entropi', 0.0028053872412972694),\n",
       " ('subset', 0.0028053872412972694),\n",
       " ('explicit', 0.0027802157223604652),\n",
       " ('occur', 0.0027802157223604652),\n",
       " ('token', 0.0027802157223604652),\n",
       " ('logic', 0.0027802157223604652),\n",
       " ('specifi', 0.0027802157223604652),\n",
       " ('materi', 0.0027802157223604652),\n",
       " ('expert', 0.0027802157223604652),\n",
       " ('whose', 0.0027802157223604652),\n",
       " ('smaller', 0.0027802157223604652),\n",
       " ('=', 0.0027684630124806993),\n",
       " ('revis', 0.0027562725821121225),\n",
       " ('forward', 0.0027562725821121225),\n",
       " ('novel', 0.0027562725821121225),\n",
       " ('extern', 0.0027562725821121225),\n",
       " ('ongo', 0.0027562725821121225),\n",
       " ('.in', 0.0027562725821121225),\n",
       " ('publicli', 0.0027562725821121225),\n",
       " ('relax', 0.0027521147866220643),\n",
       " ('n', 0.0027237807420092846),\n",
       " ('judg', 0.0027237807420092846),\n",
       " ('b', 0.0027237807420092846),\n",
       " ('lm', 0.0027237807420092846),\n",
       " ('thesauru', 0.0027237807420092846),\n",
       " ('polysemi', 0.0027189197292694757),\n",
       " ('fast', 0.0027189197292694757),\n",
       " ('r', 0.0026970666941651487),\n",
       " ('conjunct', 0.0026970666941651487),\n",
       " ('compress', 0.0026970666941651487),\n",
       " ('meet', 0.0026970666941651487),\n",
       " ('intern', 0.0026737970082933676),\n",
       " ('mwe', 0.0026737970082933676),\n",
       " ('usag', 0.0026717973726640663),\n",
       " ('calcul', 0.0026717973726640663),\n",
       " ('augment', 0.0026717973726640663),\n",
       " ('f', 0.0026717973726640663),\n",
       " ('code', 0.0026717973726640663),\n",
       " ('modif', 0.0026717973726640663),\n",
       " ('recent', 0.0026717973726640663),\n",
       " ('ip', 0.0026508591063802906),\n",
       " ('systemat', 0.0026478244974861573),\n",
       " ('latent', 0.0026478244974861573),\n",
       " ('treatment', 0.0026478244974861573),\n",
       " ('reli', 0.0026478244974861573),\n",
       " ('entir', 0.0026478244974861573),\n",
       " ('henc', 0.0026478244974861573),\n",
       " ('particularli', 0.0026478244974861573),\n",
       " ('perhap', 0.0026478244974861573),\n",
       " ('mutual', 0.0026345112655032778),\n",
       " ('vli', 0.0026311582021423282),\n",
       " ('play', 0.0026145090472909616),\n",
       " ('messag', 0.0025642430152248217),\n",
       " ('nlg', 0.0025622133594568916),\n",
       " ('guidelin', 0.0025622133594568916),\n",
       " ('servic', 0.0025622133594568916),\n",
       " ('taken', 0.0025622133594568916),\n",
       " ('yield', 0.0025622133594568916),\n",
       " ('9', 0.0025622133594568916),\n",
       " ('past', 0.0025622133594568916),\n",
       " ('difficulti', 0.0025622133594568916),\n",
       " ('hard', 0.002550018930834617),\n",
       " ('gap', 0.0025382075040308633),\n",
       " ('adjust', 0.0025382075040308633),\n",
       " ('wide', 0.0025382075040308633),\n",
       " ('assist', 0.0025382075040308633),\n",
       " ('quit', 0.0025382075040308633),\n",
       " ('care', 0.0025382075040308633),\n",
       " ('clearli', 0.0025382075040308633),\n",
       " ('proper', 0.0025382075040308633),\n",
       " ('facilit', 0.0025382075040308633),\n",
       " ('extrins', 0.0025330708499621377),\n",
       " ('student', 0.0025330708499621377),\n",
       " ('draw', 0.0025330708499621377),\n",
       " ('know', 0.0025040502583923503),\n",
       " ('insert', 0.0025040502583923503),\n",
       " ('execut', 0.0024881495285308734),\n",
       " ('replac', 0.002476903307959858),\n",
       " ('ground', 0.002476903307959858),\n",
       " ('pipelin', 0.002476903307959858),\n",
       " ('slow', 0.0024718012139826866),\n",
       " ('regress', 0.0024514026678083565),\n",
       " ('check', 0.0024514026678083565),\n",
       " ('attent', 0.0024514026678083565),\n",
       " ('degre', 0.0024514026678083565),\n",
       " ('pronoun', 0.0024514026678083565),\n",
       " ('bayesian', 0.0024514026678083565),\n",
       " ('and/or', 0.0024514026678083565),\n",
       " ('perspect', 0.0024514026678083565),\n",
       " ('subsequ', 0.0024514026678083565),\n",
       " ('minim', 0.0024514026678083565),\n",
       " ('note', 0.0024514026678083565),\n",
       " ('syntax-bas', 0.0024514026678083565),\n",
       " ('categor', 0.0024514026678083565),\n",
       " ('monolingu', 0.0024514026678083565),\n",
       " ('refashion', 0.0024287614173621494),\n",
       " ('i.e', 0.002427360024748634),\n",
       " ('confirm', 0.002427360024748634),\n",
       " ('1.', 0.002427360024748634),\n",
       " ('substitut', 0.002427360024748634),\n",
       " ('boost', 0.002427360024748634),\n",
       " ('formul', 0.002427360024748634),\n",
       " ('manner', 0.002427360024748634),\n",
       " ('7.', 0.002427360024748634),\n",
       " ('last', 0.002427360024748634),\n",
       " ('1999', 0.002427360024748634),\n",
       " ('enlarg', 0.002427360024748634),\n",
       " ('10', 0.002427360024748634),\n",
       " ('valuabl', 0.002427360024748634),\n",
       " ('earlier', 0.002427360024748634),\n",
       " ('simultan', 0.002427360024748634),\n",
       " ('shall', 0.002427360024748634),\n",
       " ('merg', 0.0023923446916309077),\n",
       " ('multimod', 0.0023923446916309077),\n",
       " ('embed', 0.0023923446916309077),\n",
       " ('bring', 0.0023649363551483307),\n",
       " ('proposit', 0.0023649363551483307),\n",
       " ('ner', 0.0023649363551483307),\n",
       " ('tweet', 0.0023649363551483307),\n",
       " ('bleu', 0.0023649363551483307),\n",
       " ('fine-grain', 0.002339297568628755),\n",
       " ('choos', 0.002339297568628755),\n",
       " ('nois', 0.002339297568628755),\n",
       " ('usabl', 0.002339297568628755),\n",
       " ('split', 0.002339297568628755),\n",
       " ('aid', 0.002339297568628755),\n",
       " ('pragmat', 0.002339297568628755),\n",
       " ('adject', 0.002339297568628755),\n",
       " ('treat', 0.002339297568628755),\n",
       " ('ie', 0.002339297568628755),\n",
       " ('softwar', 0.002339297568628755),\n",
       " ('public', 0.002339297568628755),\n",
       " ('transit', 0.002339297568628755),\n",
       " ('outlin', 0.002315213630707892),\n",
       " ('phrase-bas', 0.002315213630707892),\n",
       " ('rule-bas', 0.002315213630707892),\n",
       " ('transcript', 0.002315213630707892),\n",
       " ('thorough', 0.002315213630707892),\n",
       " ('chunk', 0.002315213630707892),\n",
       " ('complementari', 0.002315213630707892),\n",
       " ('maintain', 0.002315213630707892),\n",
       " ('devis', 0.002315213630707892),\n",
       " ('typic', 0.002315213630707892),\n",
       " ('call', 0.002315213630707892),\n",
       " ('four', 0.002315213630707892),\n",
       " ('spanish', 0.002315213630707892),\n",
       " ('assum', 0.002315213630707892),\n",
       " ('compound', 0.0022793271246442856),\n",
       " ('seed', 0.0022793271246442856),\n",
       " ('maximum', 0.002251618533299678),\n",
       " ('biomed', 0.002251618533299678),\n",
       " ('keep', 0.002251618533299678),\n",
       " ('aggreg', 0.002251618533299678),\n",
       " ('twitter', 0.002251618533299678),\n",
       " ('cooper', 0.002228834793548652),\n",
       " ('spatial', 0.002228834793548652),\n",
       " ('bel', 0.00222636463258197),\n",
       " ('year', 0.0022258224519043114),\n",
       " ('incorrect', 0.0022258224519043114),\n",
       " ('inclus', 0.0022258224519043114),\n",
       " ('noisi', 0.0022258224519043114),\n",
       " ('mainli', 0.0022258224519043114),\n",
       " ('work.in', 0.0022258224519043114),\n",
       " ('built', 0.0022258224519043114),\n",
       " ('optimis', 0.0022258224519043114),\n",
       " ('stem', 0.0022258224519043114),\n",
       " ('updat', 0.0022258224519043114),\n",
       " ('platform', 0.0022258224519043114),\n",
       " ('upon', 0.0022016918292976514),\n",
       " ('complic', 0.0022016918292976514),\n",
       " ('iii', 0.0022016918292976514),\n",
       " ('d', 0.0022016918292976514),\n",
       " ('paradigm', 0.0022016918292976514),\n",
       " ('histori', 0.0022016918292976514),\n",
       " ('key', 0.0022016918292976514),\n",
       " ('piec', 0.0022016918292976514),\n",
       " ('moreov', 0.0022016918292976514),\n",
       " ('conclud', 0.0022016918292976514),\n",
       " ('1997', 0.0022016918292976514),\n",
       " ('benchmark', 0.0022016918292976514),\n",
       " ('neg', 0.0022016918292976514),\n",
       " ('e.g.w', 0.0022016918292976514),\n",
       " ('6.', 0.0022016918292976514),\n",
       " ('write', 0.0021649262655122226),\n",
       " ('contrast', 0.0021649262655122226),\n",
       " ('judgment', 0.0021649262655122226),\n",
       " ('grow', 0.0021649262655122226),\n",
       " ('claim', 0.0021649262655122226),\n",
       " ('threshold', 0.0021368691793540178),\n",
       " ('recommend', 0.0021368691793540178),\n",
       " ('forest', 0.0021368691793540178),\n",
       " ('explain', 0.0021368691793540178),\n",
       " ('wrong', 0.0021206872851042328),\n",
       " ('disfluenc', 0.00211471534498737),\n",
       " ('shallow', 0.002110892374968448),\n",
       " ('taxonomi', 0.002110892374968448),\n",
       " ('maxim', 0.002110892374968448),\n",
       " ('polici', 0.002110892374968448),\n",
       " ('prepar', 0.002110892374968448),\n",
       " ('x', 0.0020868403278200896),\n",
       " ('other', 0.0020867085486602917),\n",
       " ('opportun', 0.0020867085486602917),\n",
       " ('state-of-the-art', 0.0020867085486602917),\n",
       " ('srl', 0.0020867085486602917),\n",
       " ('overcom', 0.0020867085486602917),\n",
       " ('obviou', 0.0020867085486602917),\n",
       " ('delet', 0.0020867085486602917),\n",
       " ('future.in', 0.0020867085486602917),\n",
       " ('background', 0.0020867085486602917),\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(tfidf.items(),key=lambda k_v: k_v[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_keys = data.keys()\n",
    "fw_keys = []\n",
    "num_FW = 0\n",
    "last_nonKey = \"\"\n",
    "for i, key in enumerate(data_keys):\n",
    "    curr_FW = data[key][-1]\n",
    "    if not (curr_FW == \"\"):\n",
    "        #print (i,curr_FW)\n",
    "        num_FW = num_FW + 1\n",
    "        fw_keys.append(key)\n",
    "    else:\n",
    "        last_nonKey = key\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12554"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fw_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_score(data, results):\n",
    "    dat_score = 0\n",
    "    t_c = 2014\n",
    "    rank = 0\n",
    "    denom = 0\n",
    "    topK = 10\n",
    "    avg_year = 0\n",
    "    avg_score = 0\n",
    "    for (key, rel_score) in results[0:topK]:\n",
    "        rank = rank + 1;\n",
    "        if (rank == 1):\n",
    "            denom = rel_score\n",
    "        t_d = data[key][2]\n",
    "        if (t_c == t_d) or (rel_score/denom < 0.01):\n",
    "            print (key, rel_score/denom)\n",
    "        dat_score = dat_score + exp(t_d - t_c)*(rel_score/denom)\n",
    "        avg_score = rel_score/denom\n",
    "        avg_year = avg_year + t_d\n",
    "        #print(key + \" \" + str(t_d))\n",
    "    print (avg_year/topK, avg_score/topK)\n",
    "    return dat_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#adds the citation of the\n",
    "def get_score_citation(data, results, citations):\n",
    "    dat_score = 0\n",
    "    t_c = 2014\n",
    "    rank = 0\n",
    "    denom = 0\n",
    "    topK = 10\n",
    "    avg_year = 0\n",
    "    avg_score = 0\n",
    "    #sum from the search engine results \n",
    "    for (key, rel_score) in results[0:topK]:\n",
    "        rank = rank + 1;\n",
    "        if (rank == 1):\n",
    "            denom = rel_score\n",
    "        t_d = data[key][2]\n",
    "        if (t_c == t_d) or (rel_score/denom < 0.01):\n",
    "            print (key, rel_score/denom)\n",
    "        dat_score = dat_score + exp(t_d - t_c)*(rel_score/denom)\n",
    "        avg_score = rel_score/denom\n",
    "        avg_year = avg_year + t_d\n",
    "        #print(key + \" \" + str(t_d))\n",
    "    \n",
    "    #does not preserve order \n",
    "    result_dic = {}\n",
    "    for (key,rel_score) in results:\n",
    "        result_dic[key] = rel_score\n",
    "        \n",
    "    for c in citations:\n",
    "        if c in result_dic:\n",
    "            rel_score = result_dic[c]\n",
    "            t_d = data[key][2]\n",
    "            dat_score = dat_score + exp(t_d - t_c)*(rel_score/denom)\n",
    "        \n",
    "    print (avg_year/topK, avg_score/topK)\n",
    "    return dat_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adds the citation of the query plus the page rank\n",
    "def get_score_citation_pr(data, results, citations, pr):\n",
    "    dat_score = 0\n",
    "    t_c = 2014\n",
    "    K = 1000\n",
    "    rank = 0\n",
    "    denom = 0\n",
    "    topK = 10\n",
    "    avg_year = 0\n",
    "    avg_score = 0\n",
    "    #sum from the search engine results \n",
    "    for (key, rel_score) in results[0:topK]:\n",
    "        rank = rank + 1;\n",
    "        if (rank == 1):\n",
    "            denom = rel_score\n",
    "        t_d = data[key][2]\n",
    "        if (t_c == t_d) or (rel_score/denom < 0.01):\n",
    "            print (key, rel_score/denom)\n",
    "        dat_score = dat_score + exp(t_d - t_c)*(rel_score/denom)\n",
    "        avg_score = rel_score/denom\n",
    "        avg_year = avg_year + t_d\n",
    "        #print(key + \" \" + str(t_d))\n",
    "    \n",
    "    #does not preserve order \n",
    "    result_dic = {}\n",
    "    for (key,rel_score) in results:\n",
    "        result_dic[key] = rel_score\n",
    "        \n",
    "    for c in citations:\n",
    "        if c in result_dic:\n",
    "            rel_score = result_dic[c]\n",
    "            t_d = data[key][2]\n",
    "            dat_score = dat_score + exp(t_d - t_c - pr*K)*(rel_score/denom)\n",
    "        \n",
    "    print (avg_year/topK, avg_score/topK)\n",
    "    return dat_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P12-1037\n",
      "we have introduced a novel approach using bayesian logic programs to learn to infer implicit information from facts extracted from natural language text.our experimental evaluation on the ic data set demonstrates the advantage of blps over logical deduction and an approach based on mlns.\n",
      "novel bayesian logic program implicit inform fact natur text experiment ic demonstr advantag blp logic deduct mln\n",
      "2004.4 0.033736165593172836\n"
     ]
    }
   ],
   "source": [
    "lta_scores = []\n",
    "indicators = ['futur', 'work', 'use', 'plan', 'model', 'improv', 'system', 'research', 'method', 'featur', 'includ', 'investig', 'explor', 'direct', 'languag', 'would', 'data', 'evalu', 'approach', 'perform']\n",
    "uninformative_fw = 0\n",
    "for key in fw_keys[:1]:\n",
    "    print(key)\n",
    "    future_work_section = data[key][9]\n",
    "    abstract_section = data[key][6]\n",
    "    query = future_work_section \n",
    "    print (query)\n",
    "    phrases = \" \".join(example_pos.get_phrases(query))\n",
    "    clean_query = \"\"\n",
    "    for item in phrases.split():\n",
    "        if not( item in indicators):\n",
    "            clean_query = clean_query + \" \" + item\n",
    "    print (clean_query.strip())\n",
    "    if not( clean_query.strip() == \"\"):\n",
    "        result = Retrieve(clean_query.strip(),index,1000,'nofeedback',0.1,10,50,0.9)# [0:10]\n",
    "        #lta_scores.append( (key,get_score(data,result) )  )\n",
    "        #lta_scores.append( (key,get_score_citation(data, result, data[key][5]) )  )\n",
    "        lta_scores.append( (key,get_score_citation(data, result, data[key][5], data[key][-1]) )  )\n",
    "    else:\n",
    "        uninformative_fw = uninformative_fw + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Helpfulness-Guided Review Summarization',\n",
       " ['Xiong, Wenting'],\n",
       " 2013,\n",
       " 'NAACL',\n",
       " ['C08-1103',\n",
       "  'E09-1059',\n",
       "  'P08-1031',\n",
       "  'P11-2088',\n",
       "  'D09-1032',\n",
       "  'W12-3708',\n",
       "  'C10-1039',\n",
       "  'H05-1043',\n",
       "  'N10-1122',\n",
       "  'P11-1150',\n",
       "  'P08-1036',\n",
       "  'W06-1650',\n",
       "  'E06-1039',\n",
       "  'P12-1036'],\n",
       " ['CIn1', 'CIn2'],\n",
       " '\\nreview mining and summarization has been a hot topic for the past decade.\\na lot of effort has been devoted to aspect detection and sentiment analysis under the assumption that every review has the same utility for related tasks.\\nhowever, reviews are not equally helpful as indicated by user-provided helpfulness assessment associated with the reviews.\\nin this thesis, we propose a novel review summarization framework which summarizes review content under the supervision of automated assessment of review helpfulness.\\nthis helpfulness-guided framework can be easily adapted to traditional review summarization tasks, for a wide range of domains.',\n",
       " '\\n2 related work  the proposed work is grounded in the following areas: review-helpfulness analysis, review summarization and supervised topic modeling.\\nin this section, we will discuss existing work in the literature and explain how the proposed work relates to them.\\nin the literature, most researchers take a supervised approach in modeling review helpfulness.\\nthey either aggregate binary helpfulness votes for each review into a numerical score, or directly use numerical helpfulness ratings.\\nkim et.\\nal (2006) took the first attempt, using regression to model review helpfulness based on various linguistic features.\\nthey reported that the combination of review length, review unigrams and product rating statistics performed best.\\nalong this line, other studies showed the perceived review helpfulness depends not only on the review content, but also on some other factors.\\nghose et.\\nal (2008) found that the reviewer?s reviewing history also matters.\\nhowever, they observed that review-subjectivity, review-readability and other reviewer-related features are interchangeable for predicting review helpfulness.\\nin addition, the empirical study on amazon reviews conducted by danescu-niculescu-mizil et.\\nal (2009) revealed that the perceived helpfulness is also affected by how a review relates to the other reviews of the same product.\\nhowever, given our goal of using review helpfulness assessment to guide summarization towards generating more useful summaries rather than to explain each individual helpfulness rating, we will ignore the interaction of helpfulness assessment among reviews of the same target.\\nfurthermore, the utility of features in modeling review helpfulness may vary with the review domain.\\nmudambi et.\\nal (2010) showed that for product reviews, the product type moderates both the product ratings and review length on the perceived review helpfulness.\\nfor educational peer reviews, in x (2011) we showed that cognitive constructs which predict feedback implementation can further improve our helpfulness model upon general linguistic features.\\nthese findings seem to suggest that the review helpfulness model should be domaindependent, due to the specific semantics of ?helpfulness?\\ndefined in context of the domain.\\none major paradigm of review summarization is aspect-based summarization, which is based on identifying aspects and associating opinion sentiment with them.\\n(although this line of work is closely related to sentiment analysis, it is not the focus of this proposed work.)\\nwhile initially people use information retrieval techniques to recognize aspect terms and opinion expressions (hu and liu, 2004; popescu and etzioni, 2005), recent work seems to favor generative statistical models more (mei et al, 2007; lu and zhai, 2008; titov and mcdonald, 2008b; titov and mcdonald, 2008a; blei and mcauliffe, 2010; brody and elhadad, 2010; mukherjee and liu, 2012; sauper and barzilay, 2013).\\none typical problem with these models is that many discovered aspects are not meaningful to end-users.\\nsome of these studies focus on distinguishing aspects in terms of sentiment variation by modeling aspects together with sentiment (titov and mcdonald, 2008a; lu and zhai, 2008; mukherjee and liu, 2012; sauper and barzilay, 2013).\\nhowever, little attention is given to differentiating review content directly regarding their utilities in review exploration.\\nmukherjee and liu (2012) attempted to address this issue by introducing user-provided aspect terms as seeds for learning review aspects, though this approach might not be easily generalized to other domains, as users?\\npoint of interest could vary with the review domain.\\nanother paradigm of review summarization is more summarization-oriented.\\nin contrast, such approaches do not require the step of identifying aspects, instead, they either assume the input text share the same aspect or aim to produce general summaries.\\nthese studies are closely related to the traditional nlp task of text summarization.\\ngenerally speaking, the goal of text summarization is to retain the most important points of the input text within a shorter length.\\neither extractively or abstractively,  one important task is to determine the informativeness of a text element.\\nin addition to reducing information redundancy, different heuristics were proposed within the context of opinion summarization.\\nstoyanov and cardie (2008) focused on identifying opinion entities (opinion, source, target) and presenting them in a structured way (templates or diagrams).\\nlerman et.\\nal (2009) reported that users preferred sentiment informed summaries based on their analysis of human evaluation of various summarization models, while kim and zhai (2009) further considered an effective review summary as representative contrastive opinion pairs.\\ndifferent from all above, ganesan et.\\nal (2010) represented text input as token-based graphs based on the token order in the string.\\nthey rank summary candidates by scoring paths after removing redundant information from the graph.\\nfor any summarization framework discussed above, the helpfulness of the review elements (e.g.\\nsentences, opinion entities, or words), which can be derived from the review overall helpfulness, captures informativeness from another dimension that has not been taken into account yet.\\nas review summarization is meant to help users acquire useful information effectively, what and how to summarize may vary with user needs.\\nto discover user preferences, ando and ishizaki (2012) manually analyzed travel reviews to identify the most influential review sentences objectively and subjectively, while mukherjee and liu (2012) extract and categorize review aspects through semi-supervised modeling using user-provided seeds (categories of terms).\\nin contrast, we are interested in using userprovided helpfulness ratings for guidance.\\nas these helpfulness ratings are existing meta data of reviews, we will need no additional input from users.\\nspecifically, we propose to use supervised lda (blei and mcauliffe, 2010) to model review content under the supervision of review helpfulness ratings.\\nsimilar approach is widely adopted in sentiment analysis, where review aspects are learned in the presence of sentiment predictions (blei and mcauliffe, 2010; titov and mcdonald, 2008a).\\nfurthermore, branavan et.\\nal (2009) showed that joint modeling of text and user annotations benefits extractive summarization.\\ntherefore, we hypothesize modeling review content together with review helpfulness is beneficial to review summarization as well.',\n",
       " '\\nthe proposed thesis mainly contributes to review mining and summarization.\\n1.\\ninvestigate the impact of the source of review content on review helpfulness.\\nwhile a lot of studies focus on product reviews, we based our analysis on a wider range of domains, including peer reviews, which have not been well studied before.\\n2.\\npropose two models to automatically assess review helpfulness at different levels of granularity.\\nwhile the review-level global helpfulness model takes into account domain-specific semantics of helpfulness of reviews, the local helpfulness model learns review helpfulness jointly with review topics.\\nthis local helpfulness model allows us to decompose overall review helpfulness into small elements, so that review helpfulness can be easily combined with metrics of other dimensions in assessing the importance of summarization candidates.\\n3.\\npropose a user-centric review summarization framework that utilizes user-provided helpfulness assessment as supervision.\\ncompared with previous work, we take a data driven approach in modeling review helpfulness as well as helpfulness-related topics, which requires no extra human input of user-preference and can be adapted to typical review summarization tasks such as aspect selection/ranking, summary sentence ordering, etc.',\n",
       " '']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Debug\n",
    "data['N13-2011']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info http://www.nltk.org/nltk_data/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_scores = sorted(lta_scores, key=lambda x: x[1],reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('W07-0204', 0.7376442998215295),\n",
       " ('P09-2022', 0.3660613894842234),\n",
       " ('W12-2202', 0.3126140511356317),\n",
       " ('N09-3010', 0.12200302618107894),\n",
       " ('J05-2005', 0.10324274397827554),\n",
       " ('P09-1050', 0.03540509724253744),\n",
       " ('P08-3001', 0.024241383071877416),\n",
       " ('W02-1510', 0.022534243176556785),\n",
       " ('I05-3018', 0.021915779847156317)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_scores[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Automatically Predicting Peer-Review Helpfulness',\n",
       " ['Xiong, Wenting', ' Litman, Diane J.'],\n",
       " 2011,\n",
       " 'Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies',\n",
       " ['W06-1650', 'W09-3605', 'P05-1012', 'C00-1072'],\n",
       " ['N13-2011', 'W12-2020', 'W13-5008', 'W11-1402'],\n",
       " '\\nidentifying peer-review helpfulness is an important task for improving the quality of feedback that students receive from their peers.\\nas a first step towards enhancing existing peerreview systems with new functionality based on helpfulness detection, we examine whether standard product review analysis techniques also apply to our new context of peer reviews.\\nin addition, we investigate the utility of incorporating additional specialized features tailored to peer review.\\nour preliminary results show that the structural features, review unigrams and meta-data combined are useful in modeling the helpfulness of both peer reviews and product reviews, while peer-review specific auxiliary features can further improve helpfulness prediction.',\n",
       " '\\n1 introduction  peer reviewing of student writing has been widely used in various academic fields.\\nwhile existing web-based peer-review systems largely save instructors effort in setting up peer-review assignments and managing document assignment, there still remains the problem that the quality of peer reviews is often poor (nelson and schunn, 2009).\\nthus to enhance the effectiveness of existing peer-review systems, we propose to automatically predict the helpfulness of peer reviews.\\nin this paper, we examine prior techniques that have been used to successfully rank helpfulness for product reviews, and adapt them to the peer-review domain.\\nin particular, we use an svm regression algorithm to predict the helpfulness of peer reviews based on generic linguistic features automatically mined from peer reviews and students?\\npapers, plus specialized features based on existing knowledge about peer reviews.\\nwe not only demonstrate that prior techniques from product reviews can be successfully tailored to peer reviews, but also show the importance of peer-review specific features.',\n",
       " '\\nthe contribution of our work is three-fold: 1) our work successfully demonstrates that techniques used in predicting product review helpfulness ranking can be effectively adapted to the domain of peer reviews, with minor modifications to the semantic and metadata features.\\n2) our qualitative comparison shows that the utility of generic features (e.g.\\nmeta-data features) in predicting review helpfulness varies between different review types.\\n3) we further show that prediction performance could be improved by incorporating specialized features that capture helpfulness information specific to peer reviews.\\nin the future, we would like to replace the manually coded peer-review specialized features (cogs) with their automatic predictions, since we have already shown in our prior work that some important cognitive-science constructs can be successfully identified automatically.5 also, it is interesting to observe that the average helpfulness ratings assigned by experts (used as the gold standard in this study) differ from those given by students.\\nprior work on this corpus has already shown that feedback features of review comments differ not only between students and experts, but also between the writing and the content experts (patchan et al, 2009).\\nwhile patchan et al (2009) focused on the review comments, we hypothesize that there is also a difference in perceived peer-review helpfulness.\\ntherefore, we are planning to investigate the impact of these different helpfulness ratings on the utilities of features used in modeling peer-review helpfulness.\\nfinally, we would like to integrate our helpfulness model into a web-based peer-review system to improve the quality of both peer reviews and paper revisions.',\n",
       " '\\nin the future, we would like to replace the manually coded peer-review specialized features (cogs) with their automatic predictions, since we have already shown in our prior work that some important cognitive-science constructs can be successfully identified automatically.5 also, it is interesting to observe that the average helpfulness ratings assigned by experts (used as the gold standard in this study) differ from those given by students.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['P11-2088']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
