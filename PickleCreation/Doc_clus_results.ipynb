{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Best Result---------\n",
      "Clusters in Basic:9 Size: 29\n",
      "Clusters in Expanded:11 Size: 36\n",
      "CommonCount:8\n",
      "goodNess:0.24615384615384617\n",
      "threshhold0.3\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "chauThresh = [0.2,0.3,0.4,0.5]\n",
    "goodNess = 0\n",
    "for i in range(2,22):\n",
    "    for j in range(2,22):\n",
    "        if i==j:\n",
    "            continue\n",
    "        else: \n",
    "            for threshhold in chauThresh:\n",
    "                basicDictpickle = open('../output/DocClus_BasicFWK_'+str(i)+'T_'+ str(threshhold)+ '.pk', 'rb')\n",
    "                basicDict_Index = pickle.load(basicDictpickle)\n",
    "                expandedDictpickle = open('../output/DocClus_ExpandedFWK_'+str(j)+'T_'+ str(threshhold)+ '.pk', 'rb')\n",
    "                expandedDict_Index = pickle.load(expandedDictpickle)\n",
    "                commonCount = 0\n",
    "                for key in expandedDict_Index:\n",
    "                    if key in basicDict_Index:\n",
    "                        commonCount += 1\n",
    "                tempGoodness = commonCount/((len(basicDict_Index) + len(expandedDict_Index))/2)\n",
    "                if tempGoodness > goodNess:\n",
    "                    goodNess = tempGoodness\n",
    "                    common = commonCount\n",
    "                    BasicK = i\n",
    "                    thresh = threshhold\n",
    "                    ExpandedK = j\n",
    "                    BSize = len(basicDict_Index)\n",
    "                    Esize = len(expandedDict_Index)\n",
    "#     print (str(i) + \":\" + str(j) + \":\" + str(threshhold))            \n",
    "print(\"------Best Result---------\")           \n",
    "print(\"Clusters in Basic:\" + str(BasicK) + \" Size: \" + str(BSize))\n",
    "print(\"Clusters in Expanded:\" + str(ExpandedK)+ \" Size: \" + str(Esize))\n",
    "print(\"CommonCount:\" +  str(common))\n",
    "print(\"goodNess:\" +  str(goodNess))\n",
    "print(\"threshhold\" + str(thresh))\n",
    "print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "basicDictpickle = open('../output/DocClus_BasicFWK_9T_0.3.pk', 'rb')\n",
    "basicDict_Index = pickle.load(basicDictpickle)\n",
    "top5 = []\n",
    "for key in basicDict_Index:\n",
    "    top5.append((key,basicDict_Index[key][1]))\n",
    "print(len(top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top5final = sorted(top5,key=lambda k_v: k_v[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4558"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pickle.load(open('AllDataPickle_basicFWPR.pk','rb'))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank - 0\n",
      "in future work, we plan to explore several extensions to our proposed method.first, we plan to use our user-feedback method in combination with existing methods (e.g., bekkerman et al (2007)) for improving its performance.second, since none of the steps in our method is specifically designed for sentiment classification, we plan to apply it to other non-topic-based text classification tasks.\n",
      "Rank - 1\n",
      "in the future, we plan to improve and extend this work in several directions.in the future, we plan to experiment with more sophisticated strategies, e.g.secondly, we plan to investigate other semisupervised methods, for example, the expectationmaximization (em) algorithm.besides looking for optimal ml strategies, we plan to look for optimal features for the task.we  plan to look into ways of reducing the sparse data problem in features, e.g.in the future, we plan to investigate the usefulness of weakly-supervised learning for identifying other schemes of information structure, e.g.finally, an important avenue of future research is to evaluate the usefulness of weakly-supervised identification of information structure for nlp tasks such as summarization and information extraction (tbahriti et al, 2006; ruch et al, 2007), and for practical tasks such as manual review of scientific papers for research purposes (guo et al, 2010).\n",
      "Rank - 2\n",
      "Rank - 3\n",
      "there are some ways in which this research could be continued in the future.\n",
      "Rank - 4\n",
      "incorporating this model in a larger syntacticallyaware model, which could benefit from the local context as well as the document level context, is an important component of future research.\n",
      "Rank - 5\n",
      "in future work, we will examine the ability of grounded language models to improve performance for other natural language tasks that exploit text based language models, such as machine translation.in future work, we will examine the strengths and limitations of grounded language modeling in these domains.\n",
      "Rank - 6\n",
      "in the future, we would like to further investigate whether syntactic and semantic analysis could be integrated more tightly.\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i,(key,score) in enumerate(top5final):\n",
    "    \n",
    "    print(\"Rank - \" + str(i))\n",
    "    if key in data :\n",
    "        if len(data[key][9]) > 0: \n",
    "            count = count + 1\n",
    "            print (data[key][9])\n",
    "        \n",
    "    if count > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
